{"cells":[{"cell_type":"markdown","source":["# Clasificación: homework\n","\n","------------------------------------------------------\n","\n","\n","### Data Science and Machine Learning\n","\n","#### Febrero 2023\n","\n","**Aurora Cobo Aguilera**\n","\n","**The Valley**\n","\n","------------------------------------------------------"],"metadata":{"id":"kR0kVlfDTixz"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"2vTCUSkBTO_a"},"outputs":[],"source":["from IPython.core.display import Image, display\n","%matplotlib inline\n","%config InlineBackend.figure_format = 'retina'  \n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","\n","from scipy.stats import multivariate_normal, norm\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.linear_model import LogisticRegression as LR\n","\n","from warnings import filterwarnings\n","filterwarnings('ignore')\n","\n","# Configuración de las figuras matplotlib\n","plt.rcParams['figure.figsize'] = [8, 6]\n","plt.rcParams.update({'font.size': 12})"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4H5R4hLbTO_b"},"outputs":[],"source":["def load_data():\n","  data = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/statlog/german/german.data',\n","                     delimiter=\" \",\n","                     header=None)\n","  data.columns=['existingchecking', \n","                'duration', \n","                'credithistory', \n","                'purpose', \n","                'creditamount', \n","                'savings', \n","                'employmentsince', \n","                'installmentrate', \n","                'statussex', \n","                'otherdebtors', \n","                'residencesince', \n","                'property', \n","                'age', \n","                'otherinstallmentplans', \n","                'housing', \n","                'existingcredits', \n","                'job', \n","                'peopleliable', \n","                'telephone', \n","                'foreignworker', \n","                'target'\n","                ]\n","  data.loc[:,'target'] = data['target'].replace([1,2],[1,0])\n","  return data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Hcou-dJ8TO_c"},"outputs":[],"source":["def muestra_frontera(X_train,Y_train,x1_grid=None,x2_grid=None,probs_grid=None,dataset=False,frontera=False,thresholds=[0.5],\n","                     prob_levels=False, titulo='Datos',xlabel='$x_1$',ylabel='$x_2$'):\n","    \n","    \"\"\"\n","    - dataset=True --> Representamos solo el dataset\n","    - frontera=True --> Representamos dataset con frontera de decisión (podemos especificar mas niveles con thresholds)\n","    - prob_levels=True --> Representamos dataset con curvas de nivel de probabilidad de clase 1.\n","    \"\"\"\n","    \n","    clases = np.unique(Y_train).astype(np.int32)\n","    labels = ['Class ' + str(int(c)) for c in clases]\n","    \n","    if(dataset==True):\n","        \n","        plt.figure()\n","        for c in clases:\n","            plt.plot(X_train[Y_train==c,0],X_train[Y_train==c,1],'s',label=labels[c])\n","        plt.xlabel(xlabel)\n","        plt.ylabel(ylabel)\n","        plt.legend(loc='upper right')\n","        plt.title(titulo)\n","        plt.grid(b=True, which='major', color='gray', alpha=0.6, linestyle='dotted', lw=1.5)\n","        plt.show()\n","    \n","    if(frontera==True):\n","        plt.figure()\n","        for c in clases:\n","            plt.plot(X_train[Y_train==c,0],X_train[Y_train==c,1],'s',label=labels[c])\n","        plt.contour(x1_grid,x2_grid,np.reshape(probs_grid[:,1],np.shape(x1)),thresholds,linestyles='dashed')\n","        plt.xlabel(xlabel)\n","        plt.ylabel(ylabel)\n","        plt.legend(loc='upper right')\n","        plt.title(titulo)\n","        # Principales líneas de la rejilla\n","        plt.grid(b=True, which='major', color='gray', alpha=0.6, linestyle='dotted', lw=1.5)\n","        plt.show()\n","\n","    if(prob_levels==True):\n","        fig,ax = plt.subplots()\n","        for c in clases:\n","            ## Dibujamos los datos de entrenamiento\n","            plt.plot(X_train[Y_train==c,0],X_train[Y_train==c,1],'s',label=labels[c])\n","        cs = ax.contourf(x1_grid,x2_grid,np.reshape(probs_grid[:,1],np.shape(x1)),np.arange(0,1.1,0.0005),linestyles='dashed',cmap='Greys')\n","        cbar = fig.colorbar(cs)\n","        plt.xlabel(xlabel)\n","        plt.ylabel(ylabel)\n","        plt.legend(loc='upper right')\n","        plt.title(titulo)\n","        # Principales líneas de la rejilla\n","        plt.grid(b=True, which='major', color='gray', alpha=0.6, linestyle='dotted', lw=1.5)\n","        plt.show()\n"]},{"cell_type":"markdown","metadata":{"id":"p0xR8n4zTO_g"},"source":["# Ejercicio 1\n","---\n","\n","En este primer ejercicio, vamos a recuperar uno de los conjunto de datos de 2 dimensiones que usamos en la sesión de clasificación.\n","\n","En el siguiente código lo cargamos, normalizamos y dividimos en train/test.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xuCNMPQVTO_g"},"outputs":[],"source":["data_ejemplo2 = pd.read_csv('http://www.tsc.uc3m.es/~olmos/BBVA/ejemplo2.txt',header=None)\n","\n","data_ejemplo2.head(10)\n","\n","data = np.array(data_ejemplo2)\n","\n","## Dimensiones\n","dims=np.shape(data)\n","N=dims[0]\n","\n","## Separamos X e Y\n","X2=data[:,0:2]\n","Y2=data[:,2]\n","\n","# Separamos train de test\n","X02_train, X02_test, Y2_train, Y2_test = train_test_split(X2, Y2, test_size=0.2, random_state=50)\n","\n","# Variables para la representación de la frontera de decisión (antes de normalizar!)\n","min1=np.min(X02_train[:,0])\n","max1=np.max(X02_train[:,0])\n","min2=np.min(X02_train[:,1])\n","max2=np.max(X02_train[:,1])\n","\n","# Normalizamos los datos (media 0, varianza 1)\n","\n","transformer = StandardScaler().fit(X02_train)\n","\n","X2_train = transformer.transform(X02_train)\n","X2_test = transformer.transform(X02_test)\n","\n","# Representaciones usando la función muestra_frontera\n","muestra_frontera(X_train=X2_train,Y_train=Y2_train,\n","                 dataset=True,titulo='Datos entrenamiento normalizados')"]},{"cell_type":"markdown","metadata":{"id":"KLF0Avj5TO_g"},"source":["En este ejercicio, vamos a entrenar un RL sobre este problema pero utilizando una representación en [**coordenadas polares**](https://es.wikipedia.org/wiki/Coordenadas_polares). Esto es, dado cada punto $\\mathbf{x}=(x_1,x_2)$, entrenaremos un RL de la forma\n","\n","\n","$$P(Y=1| {\\bf x}) =  \\frac{1}{1+\\exp(-{\\bf w}^T {\\phi(\\mathbf{x})})}=\\sigma({\\bf w}^T {\\phi(\\mathbf{x})})$$\n","\n","donde $\\phi(\\mathbf{x})=[r,a]$, $r = \\sqrt{x_1^2+x_2^2}$ y $a = \\arctan(\\frac{x_2}{x_1})$."]},{"cell_type":"markdown","metadata":{"id":"9Tl3Kz15TO_h"},"source":["### Paso 1 \n","\n","Convierta la base de datos normalizada (`X2_train`, `X2_test`) a coordenadas polares. Utilice las funciones `np.linalg.norm` para el cálculo de $r$ y `np.arctan2` para obtener $a$. "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qVscvH8JTO_h"},"outputs":[],"source":["def coordenadas_polares(X):\n","    \n","    r = np.linalg.norm(#<SOL>).reshape([-1,1])\n","    \n","    a = np.arctan2(#<SOL>).reshape([-1,1])\n","    \n","    return np.hstack([r,a])\n","\n","\n","pol_train = #<SOL> # Datos de training en polares\n","pol_test = #<SOL> # Datos de test en polares"]},{"cell_type":"markdown","metadata":{"id":"Q-4LaOgyTO_h"},"source":["### Paso 2\n","\n","Represente los datos de entrenamiento en función de $r$ y $a$. Discuta el resultado. ¿Cree que tanto $r$ como $\\alpha$ son variables igualmente discriminativas para separar las clases?"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"j05aRV3zTO_h"},"outputs":[],"source":["# Representaciones usando la función muestra_frontera\n","muestra_frontera(X_train=#<SOL>,\n","                 Y_train=#<SOL>,\n","                 dataset=True, \n","                 titulo='Datos entrenamiento, normalizados y en coordenadas polares', \n","                 xlabel = '$r$',ylabel='$a$')"]},{"cell_type":"markdown","metadata":{"id":"ueneZd4wTO_i"},"source":["### Paso 3\n","\n","Entrene un RL utilizando únicamente la variable $r$. Discuta el resultado a la vista de las representaciones obtenidas."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fNCQmRk7TO_i"},"outputs":[],"source":["# Entrenar RL en una dimension. \n","\n","from sklearn.linear_model import LogisticRegression as LR\n","\n","mi_RL_r = LR(C=1e8) \n","\n","mi_RL_r.fit(#<SOL>)\n","\n","n_points = 50\n","#Obtenemos una rejilla de puntos en los que evaluaremos nuestro RL\n","x1,x2 = np.mgrid[min1:max1:(max1-min1)/n_points, min2:max2:(max2-min2)/n_points]\n","grid = np.transpose(np.row_stack([x1.ravel(), x2.ravel()]))\n","# Normalizamos la rejilla\n","grid_norm = transformer.transform(grid)\n","\n","# Pasamos la rejilla a polares\n","grid_pol = #<SOL>\n","\n","#Estimamos la probabilidad asociada a cada punto de la rejilla con el método .predic_proba\n","probs_LR_r = mi_RL_r.predict_proba(#<SOL>)\n","\n","# Representaciones usando la función muestra_frontera \n","muestra_frontera(x1_grid=grid_norm[:,0].reshape([n_points,n_points]),\n","                 x2_grid=grid_norm[:,1].reshape([n_points,n_points]),\n","                 probs_grid=probs_LR_r,X_train=X2_train,Y_train=Y2_train,\n","                 prob_levels=True,titulo='RL datos normalizados en cartesianas')\n","\n","muestra_frontera(x1_grid=grid_pol[:,0].reshape([n_points,n_points]),\n","                 x2_grid=grid_pol[:,1].reshape([n_points,n_points]),\n","                 probs_grid=probs_LR_r,X_train=pol_train,Y_train=Y2_train,\n","                 frontera=True,titulo='RL datos normalizados en polares',xlabel = '$r$',ylabel='$a$',\n","                thresholds=[0.5,0.7,0.9])\n","\n","muestra_frontera(x1_grid=grid_pol[:,0].reshape([n_points,n_points]),\n","                 x2_grid=grid_pol[:,1].reshape([n_points,n_points]),\n","                 probs_grid=probs_LR_r,X_train=pol_train,Y_train=Y2_train,\n","                 prob_levels=True,titulo='RL datos normalizados en polares', xlabel = '$r$',ylabel='$a$')"]},{"cell_type":"markdown","metadata":{"id":"Za5YqX9fTO_i"},"source":["### Paso 4\n","\n","Calcule la fracción de datos correctamente clasificados tanto en el conjunto de entrenamiento como en el de test. Compare con los resultados obtenidos en el notebook visto en clase."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rxYTn4dZTO_i"},"outputs":[],"source":["#<SOL>\n","\n","#</SOL>"]},{"cell_type":"markdown","metadata":{"id":"1hlSwGrRTO_i"},"source":["# Ejercicio 2 \n","---\n","\n","Utilizando la base de datos *german* en la que se han codificado de forma adecuado las variables categóricas, compare las prestaciones en un conjunto de test de los siguientes clasificadores en términos de área bajo la curva ROC (AUC-ROC) y F1-score: \n","\n","- k-NN, validando el número de vecinos, la ponderación de distancias.\n","- Regresión Logística con regularización L2, validando el parámetro $C$ de regularización.\n","- LDA (Lineal Discriminant Analysis).\n","- Random Forest validando tanto el número de estimadores y el máximo número de hojas.\n","\n","Represente también en una única gráfica la curva ROC de los cuatro clasificadores. En todos los casos, seleccione rangos de validación adecuados para cada hiperparámetro.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kSsOV7b1TO_j"},"outputs":[],"source":["#<SOL>\n","\n","#</SOL>"]},{"cell_type":"markdown","metadata":{"id":"bGsQ7pt8TO_j"},"source":["# Ejercicio 3 \n","\n","En este último ejercicio, vamos a estudiar las prestaciones de un regresor logístico y un k-NN para clasificar imágenes de números. Cada imagen es de $8x8$ pixeles. Vamos a tratar los píxeles como variables independientes, así que cada dato de entrada tiene 64 dimensiones."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_XfMFBrKTO_j"},"outputs":[],"source":["from sklearn.datasets import load_digits\n","digits = load_digits()\n","\n","X = digits.data # Números\n","Y = digits.target # Etiquetas\n","\n","print(\"Hay un total de {0:d} imagenes, cada una contiene {1:d} pixels\".format(X.shape[0],X.shape[1]))"]},{"cell_type":"markdown","metadata":{"id":"YbA551fKTO_j"},"source":["Dibujemos algunas imágenes de muestra."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HVfalGvTTO_j"},"outputs":[],"source":["def plot_digits(data):\n","    fig, axes = plt.subplots(1, 10, figsize=(10, 10),\n","                             subplot_kw={'xticks':[], 'yticks':[]},\n","                             gridspec_kw=dict(hspace=0.1, wspace=0.1))\n","    for i, ax in enumerate(axes.flat):\n","        ax.imshow(data[i].reshape(8, 8),\n","                  cmap='binary', interpolation='nearest',\n","                  clim=(0, 16))\n","        \n","plot_digits(X)"]},{"cell_type":"markdown","metadata":{"id":"wcRiPRieTO_j"},"source":["En este ejercicio se pide construir dos clasificadores multi-clase basados en k-NN y regresión logística utilizando la estrategia OneVsRest. Para cada uno de ellos, se pide analizar:\n","- El número de imágenes correctamente detectadas tanto en el conjunto de entrenamiento como el de test. \n","- F1 score y precision en test de cada uno de los clasificadores binarios entrenados internamente.\n","- Matriz de confusión y la tasa de error en clasificación (tanto en train como en test) para cada número.\n","\n","Previamente, divida el conjunto de datos en entrenamiento y test y normalize las entradas."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"85UV26iOTO_k"},"outputs":[],"source":["#<SOL>\n","\n","#</SOL>"]},{"cell_type":"markdown","metadata":{"id":"5GaA4gfOTO_k"},"source":["# Ejercicio 4 \n","\n","Represente la matriz de confusión de un esquema OneVsOne y discuta las diferencias. ¿Cuántos clasificadores estamos entrenando en este caso?"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AcOJE116TO_k"},"outputs":[],"source":["#<SOL>\n","\n","#</SOL>"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.4"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}