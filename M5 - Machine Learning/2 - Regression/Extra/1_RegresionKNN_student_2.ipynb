{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNXFnVd3xH9WSAASvNx+MgY"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Modelos de Regresión\n","\n","------------------------------------------------------\n","\n","\n","### Data Science and Machine Learning\n","\n","#### Febrero 2023\n","\n","**Aurora Cobo Aguilera**\n","\n","**The Valley**\n","\n","------------------------------------------------------"],"metadata":{"id":"SQjVdWtZFtVr"}},{"cell_type":"markdown","source":["Este notebook es una réplica del segundo de regresión, con el cambio de implementar el modelo del KNN sin la librería de sklearn. Puedes intentar descifrar el código del algoritmo para practicar más sobre programación y entender mejor el modelo.\n","\n","## 1. Regresión *k*-nearest neighbors (*k*NN)\n","\n","En este notebook describiremos la siguiente tarea de regresión que vamos a estudiar. Se trata de la regresión *k*NN, un modelo no paramétrico."],"metadata":{"id":"Eu2rnzBDFq2Y"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Fdl6m-gnFogY"},"outputs":[],"source":["%matplotlib inline \n","\n","import matplotlib\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pylab\n","\n","import scipy.io       \n","import pandas as pd   \n","\n","\n","pylab.rcParams['figure.figsize'] = 9, 6  "]},{"cell_type":"markdown","source":["### 1.1. Cargar los datasets a usar\n","\n","El dataset es una adaptación del <a href=http://www.dcc.fc.up.pt/~ltorgo/Regression/DataSets.html> dataset `STOCK`</a>, cogido originalmente del repositorio StatLib. El objetivo de este problema es predecir los valores de las acciones de una empresa aeroespacial determinada, dados los valores de otras 9 empresas en el mismo día.  \n","\n","Puedes explorar los resultados del siguiente notebook usando dos datasets alternativos: \n","\n","\n","* El  <a href=https://archive.ics.uci.edu/ml/datasets/Concrete+Compressive+Strength> dataset `CONCRETE` </a> obtenido del <a href=https://archive.ics.uci.edu/ml/index.html> repositorio de Machine Learning en la Universidad de California Irvine</a>. Para ello, simplemente elige `CONCRETE` en la variable ds_name y no `STOCK` en la siguiente celda. Recuerda que debes correr las celdas de nuevo para ver los cambios. El objetivo del dataset `CONCRETE` es predecir la fuerza compresiva de mezclas de cemento basadas en variables observadas relacionadas con la composición de la mezcla y la antigüedad del material. \n","\n","* El dataset `Advertising`, es obtenido del libro <a href=https://www.statlearning.com/> An Introduction to Statistical Learning with applications in R</a> de los autores: G. James, D. Witten, T. Hastie and R. Tibshirani. El objetivo de dicho problema es predecir las ventas de un producto dado, conociendo la inversión en diferentes sectores de publicidad. Más específicamente, las variables de entrada y salida se describen de la siguiente manera:\n","\n","  - *Variables de entrada:*\n","     * TV: dólares de publicidad gastados en TV para un único producto en un mercado determiando (en miles de dólares)\n","     * Radio: dólares de publicidad gastados en Radio\n","     * Newspaper: dólares de publicidad gastados en periódicos\n","     \n","  - *Variable de salida:*\n","     * Sales: ventas de un único producto en un mercado determinado (en miles de widgets)\n","     \n","Puedes echar un vistazo al archivo `Advertising.csv` para tener una idea de la estructura de los datos."],"metadata":{"id":"DCvTI2WoGvuI"}},{"cell_type":"markdown","source":["Empecemos cargando los datos en el espacio de trabajo, y visualizando las dimensiones de todas las matrices."],"metadata":{"id":"f4n4__9MPFu6"}},{"cell_type":"code","source":["# Selecciona el dataset: 'stock', 'concrete' or 'advertising'\n","nombre_dataset = 'stock'\n","\n","if nombre_dataset == 'stock':\n","    # STOCK DATASET\n","    data = scipy.io.loadmat('stock.mat')\n","    X_tr = data['xTrain']\n","    Y_tr = data['sTrain']\n","    X_tst = data['xTest']\n","    Y_tst = data['sTest']\n","\n","elif nombre_dataset == 'concrete':\n","    # CONCRETE DATASET. \n","    data = scipy.io.loadmat('concrete.mat')\n","    X_tr = data['X_tr']\n","    Y_tr = data['S_tr']\n","    X_tst = data['X_tst']\n","    Y_tst = data['S_tst']\n","\n","elif nombre_dataset == 'advertising':    \n","    # ADVERTISING DATASET\n","    df = pd.read_csv('Advertising.csv', header=0)\n","    X_tr = df.values[:150, 1:4]\n","    Y_tr = df.values[:150, -1]\n","    X_tst = df.values[150:, 1:4]\n","    Y_tst = df.values[150:, -1]\n","\n","else:\n","    print('Dataset desconocido')\n","\n","# Muestra las dimensiones de los datos\n","print(X_tr.shape)\n","print(Y_tr.shape)\n","print(X_tst.shape)\n","print(Y_tst.shape)"],"metadata":{"id":"glR5JB70FqKg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"54vO_txYx3sd"},"source":["### 1.2. Visualizar los datos\n","\n","Podemos obtener una severa idea sobre la tarea de regresión representando el *gráfico disperso* de cada variable unidimensional contra la variable objetivo."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ABWFMGYwx3sd"},"outputs":[],"source":["pylab.subplots_adjust(hspace=0.2)\n","\n","for idx in range(X_tr.shape[1]):\n","    ax1 = plt.subplot(3, 3, idx+1)\n","    ax1.plot(X_tr[:, idx], Y_tr, '.')\n","    ax1.get_xaxis().set_ticks([])\n","    ax1.get_yaxis().set_ticks([])\n","\n","plt.show()"]},{"cell_type":"markdown","source":["> **Ejercicio**: Modifica la celda anterior para añadir los nombres a los ejes, poniendo X0, X1,... según la variable que se está dibujando, y 'Y' para el eje y con la variable objetivo."],"metadata":{"id":"j35bbIsgrN9F"}},{"cell_type":"markdown","metadata":{"id":"CzbgErOLx3se"},"source":["### 1.3. Estimador referencia/*baseline*. Usando la media de la etiquetas del conjunto de entrenamiento\n","\n","Un primer método muy sencillo para construir un modelo de regresión es usar la media de todos los valores objetivo en el conjunto de entrenamiento como la salida, descartando los valores del vector de las observaciones de entrada.\n","\n","Este enfoque se puede considerar como un ***baseline***, dado que cualquier otro método haciendo uso efectivo de las variables de entrada, estadísticamente relacionado con $y$, debería mejorarlo.\n","\n","La predición entonces es dada por\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DpPWpwsVx3se"},"outputs":[],"source":["# Media de todas las varibles objetivo en el conjunto de entranmiento\n","y_estimada = np.mean(Y_tr)\n","print (y_estimada)"]},{"cell_type":"markdown","metadata":{"id":"XY6H23rax3sf"},"source":["para cualquier entrada ${\\bf x}$."]},{"cell_type":"markdown","metadata":{"id":"SD24KQ0Vx3sf"},"source":["> **Ejercicio**: Calcula el MSE sobre los conjuntos de entrenamiento y test para el método de estimación *baseline*.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_j_Na6Cqx3sg"},"outputs":[],"source":["# Definimos una función que calcula el MSE\n","def error_cuadratico(y, y_est):\n","    # Squeeze se usa para asegurarnos de las dimensiones adecuadas\n","    error = np.mean((y - y_est)**2)\n","    return error\n","\n","# MSE del baseline sobre los datos de entrenamiento\n","# MSE_tr = <SOL>\n","\n","# MSE del baseline sobre los datos de test\n","# MSE_tst = <SOL>\n","\n","print('MSE en el conjunto de entrenamiento (baseline): {0}'.format(MSE_tr))\n","print('MSE en el conjunto de test (baseline): {0}'.format(MSE_tst))  "]},{"cell_type":"markdown","metadata":{"id":"i-NSBxPex3sg"},"source":["Ten en cuenta que en la pieza de código anterior, la función 'error_cuadratico' se puede usar cuando el segundo argumento es un número en vez de un vector con la misma longitud que el primer argumento. El valor se restará de cada una de las componentes del vector dado como primer argumento. "]},{"cell_type":"markdown","metadata":{"id":"3x3d5blxx3sh"},"source":["### 1.4. Regresión unidimensional con el método $k$-nn\n","\n","Los principios del método $k$-nn son los siguientes:\n","\n","   - Para cada muestra donde hay que hacer una predicción, encuentra los $k$ vecinos más cercanos a ella (en el conjunto de entrenamiento)\n","   - Obtén una estimación promediando las etiquetas correspondientes a los vecinos seleccionados.\n","\n","El número de vecinos es un hiperparámetro que juega un papel muy importante en el rendimiento del método. \n","\n","> **Ejercicio**: Puedes comprobar su influencia cambiando $k$ en el siguiente código. En particular, puedes empezar con $k=1$ y observar el efecto de aumentar el valor de $k$."]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"id":"kSKWJNkAx3sh"},"outputs":[],"source":["# Código para implementar regresión unidimensional con K-nn\n","# Las estimaciones se hacen solo usando una variable de entrada!!\n","\n","from scipy import spatial\n","\n","var = 0         # Selecciona la variable (e.g., cualquier valor de 0 a 8 para el dataset STOCK)\n","k = 1           # Número de vecinos\n","n_points = 1000 # Número de puntos en el eje 'x' (con propósito de representación en gráficas)\n","\n","# Para la representación, calculamos la salida del modeo\n","# en una serie de puntos igualmente distribuidos en el eje x\n","grid_min = np.min([np.min(X_tr[:,var]), np.min(X_tst[:,var])])    # Valor mínimo del eje a representar y evaluar\n","grid_max = np.max([np.max(X_tr[:,var]), np.max(X_tst[:,var])])    # Valor máximo del eje a representar y evaluar\n","X_grid = np.linspace(grid_min, grid_max, num=n_points)            # Crea en eje de puntos\n","\n","def regresion_knn(X1, Y1, X2, k):\n","    \"\"\" Calcula la estimación de regresión del K-NN para las observaciones contenidas en \n","        las filas de X2, para el conjunto de entrenamiento dado por la filas de X1 y las\n","        salidas de Y1. k en el número de vecinos del algoritmo k-NN\n","    \"\"\"\n","    if X1.ndim == 1:\n","        X1 = np.asmatrix(X1).T\n","    if X2.ndim == 1:\n","        X2 = np.asmatrix(X2).T\n","    # Calcula distancias\n","    distancias = spatial.distance.cdist(X1, X2,'euclidean')\n","    # Guarda los índices de los vecinos más cercanos\n","    vecinos = np.argsort(distancias, axis=0, kind='quicksort', order=None)\n","    cercanos = vecinos[range(k),:]\n","    \n","    valores_estimados = np.zeros([X2.shape[0],1])\n","    for idx in range(X2.shape[0]):\n","        valores_estimados[idx] = np.mean(Y1[cercanos[:, idx]])\n","        \n","    return valores_estimados\n","\n","est_tst = regresion_knn(X_tr[:,var], Y_tr, X_tst[:,var], k)\n","est_grid = regresion_knn(X_tr[:,var], Y_tr, X_grid, k)\n","\n","plt.plot(X_tr[:,var], Y_tr,'b.', label='Muestras de entrenamiento')\n","plt.plot(X_tst[:,var], Y_tst,'rx', label='Muestras de test')\n","plt.plot(X_grid, est_grid,'g-', label='Modelo de regresión ')\n","plt.axis('tight')\n","plt.legend(loc='best')"]},{"cell_type":"markdown","metadata":{"id":"CTXS1Rq3x3sh"},"source":["#### 1.4.1. Evolución del error con el número de vecinos ($k$)\n","\n","Podemos ver que un valor pequeño de $k$ resulta en una curva de regresión que presenta muchas oscilaciones grandes. La curva está captando cualquier ruido que pueda estar presente en los datos de entrenamiento y <i>**sobreajusta**</i> el conjunto de entrenamiento. Por otro lado, coger un valor de $k$ muy grande (e.g., 200) hace que la curva de regresión sea muy suave, promediando los valores de las etiquetas en el conjunto de entrenamiento sobre un intervalo muy grande de las variables de observación.\n","\n","El siguiente código ilustra este efecto, dibujando los errores cuadráticos promedio de entrenamiento y test como una función de $k$. "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"n0JzqdRdx3si"},"outputs":[],"source":["var = 0\n","k_max = 60\n","\n","#<SOL>\n","\n","#</SOL>\n","\n","k_max = np.minimum(k_max, X_tr.shape[0])  # k_max no puede ser mayor que el número de muestras\n","\n","\n","# Ten cuidado con el uso de range, e.g., range(3) = [0,1,2] and range(1,3) = [1,2]\n","MSEk_tr = [error_cuadratico(Y_tr, regresion_knn(X_tr[:, var], Y_tr, X_tr[:, var], k)) \n","           for k in range(1, k_max+1)]\n","MSEk_tst = [error_cuadratico(Y_tst, regresion_knn(X_tr[:, var], Y_tr, X_tst[:, var], k)) \n","            for k in range(1, k_max+1)]\n","\n","kgrid = np.arange(1, k_max+1)\n","plt.plot(kgrid, MSEk_tr,'bo', label='MSE entrenamiento')\n","plt.plot(kgrid, MSEk_tst,'ro', label='MSE test')\n","plt.xlabel('$k$')\n","plt.axis('tight')\n","\n","plt.legend(loc='best')\n"]},{"cell_type":"markdown","metadata":{"id":"uji2tU59x3si"},"source":["Como podemos ver, el error inicialmente disminuye alcanzando un mínimo, en el conjunto de test, para algún valor finito de $k$ ($k\\approx 10$ para el dataset `STOCK`). Aumentar el valor de $k$ más alla de este número, empobrece el rendimiento del modelo."]},{"cell_type":"code","source":["error_cuadratico(Y_tr, regresion_knn(X_tr[:, var], Y_tr, X_tr[:, var], 1))"],"metadata":{"id":"7JiyDJ4IjHY1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DyhRfUsPx3si"},"source":["> **Ejercicio**: Analiza el MSE para $k=1$. ¿Por qué es más pequeño que para otros $k$? ¿Bajo qué condiciones será exactamente cero?\n","\n","> **Ejercicio**: Modifica el código anterior para ver el MSE desde $k=1$ hasta $k$ igual al número de muestras de entrenamiento. ¿Puedes relacionar el error cuadrático del método $k$-NN con el *baseline* para algún valor de $k$? "]},{"cell_type":"markdown","metadata":{"id":"FF6o_50Bx3sj"},"source":["### 1.4.2. Influencia de la variable de entrada\n","\n","Echando un ojo a los *scatter plots*, podemos ver que alguna variable de observación parece tener una más clara relación con la variable objetivo. Entonces, podemos esperar que no todas las variables sean igualmente útiles para la tarea de regresión. En la siguiente gráfica estudiamos el rendimiento que puede alcanzar cada variable.\n","\n","Ten en cuenta que, en la práctica, las etiquetas de test no están accesibles para la selección del hiperparámetro $k$, así que debemos tener cuidado sobre las conclusiones de este experimento. Un enfoque más realista se estudiará más adelante con el concepto de validación del modelo."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gyC6nGd_x3sj"},"outputs":[],"source":["k_max = 20\n","\n","performance_variable = []\n","valores_k = []\n","\n","for var in range(X_tr.shape[1]):\n","    \n","    MSE_tr = [error_cuadratico(Y_tr, regresion_knn(X_tr[:,var], Y_tr, X_tr[:, var], k)) \n","              for k in range(1, k_max+1)]\n","    MSE_tst = [error_cuadratico(Y_tst, regresion_knn(X_tr[:,var], Y_tr, X_tst[:, var], k)) \n","               for k in range(1, k_max+1)]\n","    MSE_tr = np.asarray(MSE_tr)\n","    MSE_tst = np.asarray(MSE_tst)\n","\n","    # Seleccionamos la variable asociada al valor de k para el cual el error es mínimo\n","    pos = np.argmin(MSE_tr)\n","    valores_k.append(pos + 1)\n","    performance_variable.append(MSE_tst[pos])\n","    \n","plt.stem(range(X_tr.shape[1]), performance_variable)\n","plt.title('Resultados de la regresión unidimensional ($k$NN)')\n","plt.xlabel('Variable')\n","plt.ylabel('Test MSE')\n","\n","plt.figure(2)\n","plt.stem(range(X_tr.shape[1]), valores_k)\n","plt.xlabel('Variable')\n","plt.ylabel('$k$')\n","plt.title('Selección de los hiperparámetros')"]},{"cell_type":"markdown","source":["### 1.5. Regresión multidimensional con el método $k$-nn\n","\n","En la sección anterior, hemos estudiado el rendimiento del método $k$-nn cuando sólo usamos una variable. Hacer esto era conveniente, porque nos permitía dibujar las curvas de regresión en una figura de 2D y tener una idea sobre las consecuencias de modificar el número de vecinos.\n","\n","Para completarlo, evaluamos el rendimiento del método $k$-nn en este dataset usando todas las variables juntas. De hecho, cuando diseñas un modelo de regresión, deberías proceder de esta manera, usando toda la información disponible para hacer una estimación lo más precisa posible. De esta forma, podremos también darnos cuenta de posibles correlaciones que pueda haber entre las variables de entrada y que puedan tener información relevante para la tarea de regresión.\n","\n","Por ejemplo, en el dataset `STOCK`, podría ser que la combinación de las acciones de dos empresas de aviones sea más informativa sobre el precio objetivo de la empresa, mientras que el valor de una compañia sólo no es suficiente.\n","\n","\n","También, en el dataset `CONCRETE`, podría ser que para el problema que se trata la combinación de una gran proporción de agua con una pequeña proporción de grano grueso es un claro indicador de cierta fuerza compresiva del material, mientras la proporción de alguna de las dos sustancias por separado no sea sufiecientemente buena para obtener ere resultado.\n","\n","\n"],"metadata":{"id":"QXqwoHpLpFoO"}},{"cell_type":"code","source":["k_max = 20\n","\n","MSE_tr = [error_cuadratico(Y_tr, regresion_knn(X_tr, Y_tr, X_tr, k)) for k in range(1, k_max+1)]\n","MSE_tst = [error_cuadratico(Y_tst, regresion_knn(X_tr, Y_tr, X_tst, k)) for k in range(1, k_max+1)]\n","\n","plt.plot(np.arange(k_max)+1, MSE_tr,'bo',label='Train MSE')\n","plt.plot(np.arange(k_max)+1, MSE_tst,'ro',label='Test MSE')\n","plt.xlabel('k')\n","plt.ylabel('MSE')\n","\n","plt.legend(loc='best')"],"metadata":{"id":"WWLd2w1Yoe93"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["En este caso, podemos comprobar que el MSE en test es mucho más bajo que el que se obtenía cuando se usaba una sola variable, y también mucho mejor que el *baseline*. También es interesante ver que en este caso en particular, el mejor resultado se obtiene para un valor pequeño de $k$, con un aumento del error para valores mayores de este.\n","\n","Sin embargo, como se ha mencionado anteriormente, estos resultados se deberían interpretar con cuidado.\n","\n","**Ejercicio**: ¿Cómo seleccionaría el valor de $k$ si las etiquetas de test no están disponibles para la validación del modelo?\n"],"metadata":{"id":"VLF8i5Ju-lB2"}},{"cell_type":"markdown","metadata":{"id":"WOsF3J5hx3sk"},"source":["### 1.6. Selección de los hiperparámeteros via **cross-validation**\n","\n","Un inconveniente de la aplicación del método $k$-nn es que la selección de $k$ influye el error final del algoritmo. En experimentos anteriores, mantenemos el valor de $k$ que minimiza el MSE en el conjunto de entrenamiento. Sin embargo, vimos que la localización del mínimo no es necesariamente la misma desde la perspectiva de los datos de test. Idealmente, nos gustaría que el diseño del modelo de regresión funcione tan bien como sea posible para futuros patrones sin etiquetar que no están disponibles durante la fase de entrenamiento. Esta propiedad se llama <i>generalización</i>. Ajustamos los datos de entrenamiento con la esperanza de indirectamente obtener también un modelo que generalice bien. Para conseguir dicho objetivo, hay estrategias que intentan garantizar una correcta generalización del modelo. Una de dichas estrategias se conoce como validación cruzada o <b>cross-validation</b>, en inglés.\n","\n","Ya que no se permite usar las etiquetas de test durante el entrenamiento (debería dejarse para simular posible aplicaciones futuras del modelo en patrones no observados), necesitamos averiguar una manera de mejorar nuestra estimación de los hiperparámetros que requiera solo datos de entrenamiento.Cross-validation nos permite hacer esto siguiendo una serie de pasos: \n","\n","   - Dividir el conjunto de entrenamiento en diferentes subconjuntos (generalmente no superpuestos). Si usamos $M$ subconjuntos, el método es definido como **$M$-fold cross-validation**. Si consideramos cada muestra como un conjunto diferente, el método es definido como **leave-one-out (LOO) cross-validation**.\n","   - Entrena el sistema $M$ veces. Para cada ejecución, usa diferentes particiones como el conunto de <i>validación</i>, y usa el resto como conjunto de entrenamiento. Evalua el rendimiento para diferentes elecciones del hiperparámetro (i.e., para diferentes valores de $k$ para el método $k$-NN).\n","   - Promedia el error de validación sobre todas las paritciones, y escoge el hiperparámetro que proporcione el mínimo error de validación.\n","   - Vuelve a ejecutar el algoritmo sobre todas las muestras de entrenamiento, manteniendo el valor del hiperparámetro que elegiste del proceso de cross-validation.\n","   \n","<img src=\"https://chrisjmccormick.files.wordpress.com/2013/07/10_fold_cv.png\">"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ykPaUqnzx3sk"},"outputs":[],"source":["### Este fragmento de código ejecuta k-nn con validación cruzada M-fold \n","\n","# Parámetros:\n","M = 5       # Número de subconjuntos para M-cv\n","k_max = 40  # Máximo valor del parámetro k del knn que se va a explorar\n","\n","# Primero calculamos la curva del error de entrenamiento, que va a ser útil para comparación visual\n","MSE_tr = [error_cuadratico(Y_tr, regresion_knn(X_tr, Y_tr, X_tr, k)) for k in range(1, k_max+1)]\n","\n","## M-CV\n","# Obtenemos los índices de las observaciones para los diferentes subconjuntos\n","n_tr = X_tr.shape[0]\n","permutacion = np.random.permutation(n_tr)\n","\n","# Dividimos los índices en M subconjuntos de (casi) el mismo tamaño. \n","conjuntos_indices = {i: [] for i in range(M)}\n","i = 0\n","for pos in range(n_tr):\n","    conjuntos_indices[i].append(permutacion[pos])\n","    i = (i+1) % M\n","    \n","# Obtenemos los errores de validacion\n","MSE_val = np.zeros((1,k_max))\n","for i in range(M):\n","    val_indices = conjuntos_indices[i]\n","    \n","    # Sacamos los val_indices del conjunto de índices.\n","    tr_indices = list(set(permutacion) - set(val_indices))\n","    \n","    MSE_val_iter = [error_cuadratico(Y_tr[val_indices], regresion_knn(X_tr[tr_indices, :], Y_tr[tr_indices], X_tr[val_indices, :], k)) for k in range(1, k_max+1)]\n","\n","    MSE_val = MSE_val + np.asarray(MSE_val_iter).T\n","    \n","MSE_val = MSE_val/M\n","\n","# Selecciona el mejor k basado en el error de validación\n","k_mejor = np.argmin(MSE_val) + 1\n","\n","# Calcula el MSE de test final para el k seleccionado\n","MSE_tst = error_cuadratico(Y_tst, regresion_knn(X_tr, Y_tr, X_tst, k_mejor))\n","\n","plt.plot(np.arange(k_max)+1, MSE_tr, 'bo', label='Entrenamiento MSE')\n","plt.plot(np.arange(k_max)+1, MSE_val.T, 'go', label='Validación MSE')\n","plt.plot([k_mejor, k_mejor], [0, MSE_tst],'r-')\n","plt.plot(k_mejor, MSE_tst,'ro',label='Test MSE')\n","plt.legend(loc='best')"]},{"cell_type":"markdown","metadata":{"id":"KOdNNxIRx3sl"},"source":["**Ejercicio**: Modifica el código anterior para usar sólo una de las variables de entrada en el dataset.\n","  - Siguiendo un enfoque de validación cruzada, selecciona el mejor valor de $k$ para el $k$-nn basado solo en la variable 0.\n","  - Calcula el error de test para el valor seleccionado de $k$."]},{"cell_type":"code","source":["#<SOL>\n","\n","#</SOL>"],"metadata":{"id":"zcSKBiwOEIAZ"},"execution_count":null,"outputs":[]}]}